{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EJERCICIO 2 PROYECTO INVESTIGACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos las librerías necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import cv2\n",
    "from scipy.fft import fft2\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage import img_as_ubyte\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccionamos los directorios de las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las rutas de las diferentes carpetas\n",
    "base_path = \"objects\"\n",
    "images_path = os.path.join(base_path, \"images\")\n",
    "masks_path = os.path.join(base_path, \"masks\")\n",
    "output_path = os.path.join(base_path, \"output\")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicamos las máscaras a las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Recorremos las carpetas de imágenes\n",
    "for animal in os.listdir(images_path):\n",
    "    animal_images_path = os.path.join(images_path, animal)\n",
    "    animal_masks_path = os.path.join(masks_path, animal)\n",
    "    animal_output_path = os.path.join(output_path, animal)\n",
    "\n",
    "    if not os.path.isdir(animal_images_path) or not os.path.isdir(animal_masks_path):\n",
    "        print(f\"Carpeta faltante para {animal}, omitiendo...\")\n",
    "        continue\n",
    "\n",
    "    os.makedirs(animal_output_path, exist_ok=True)\n",
    "\n",
    "    # Recorremos las imágenes buscando la máscara correspondiente\n",
    "    for image_name in sorted(os.listdir(animal_images_path)):\n",
    "    \n",
    "        if not image_name.startswith(\"image_\") or not image_name.endswith(\".jpg\"):\n",
    "            print(f\"Archivo ignorado: {image_name}\")\n",
    "            continue\n",
    "\n",
    "        image_number = image_name.split(\"_\")[1].split(\".\")[0]  # Extrae el número de imagen\n",
    "        mask_name = f\"mask_{image_number}.png\"\n",
    "        image_path = os.path.join(animal_images_path, image_name)\n",
    "        mask_path = os.path.join(animal_masks_path, mask_name)\n",
    "\n",
    "        # Verifica que existan tanto la imagen como la máscara\n",
    "        if not os.path.exists(image_path) or not os.path.exists(mask_path):\n",
    "            print(f\"Faltan archivos para {image_name} y {mask_name}, omitiendo...\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGBA\")  \n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "            mask = mask.resize(image.size)\n",
    "\n",
    "            image_array = np.array(image)\n",
    "            mask_array = np.array(mask)\n",
    "\n",
    "            # Aplicamos la máscara a la imagen\n",
    "            image_array[mask_array == 0] = [0, 0, 0, 0] \n",
    "\n",
    "            combined_image = Image.fromarray(image_array, \"RGBA\")\n",
    "            rgb_image = combined_image.convert(\"RGB\")\n",
    "\n",
    "            # Guardamos la imagen resultante en formato JPEG\n",
    "            output_image_path = os.path.join(animal_output_path, image_name)\n",
    "            output_image_path = output_image_path.replace(\".jpg\", \"_combined.jpg\")\n",
    "            rgb_image.save(output_image_path, \"JPEG\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {image_name}: {e}\")\n",
    "\n",
    "print(\"Proceso completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etiquetamos las imágenes según su carpeta, y las guardamos en un csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas generadas en image_labels.csv\n"
     ]
    }
   ],
   "source": [
    "main_folder = \"objects/output\"\n",
    "output_csv = \"image_labels.csv\"\n",
    "\n",
    "with open(output_csv, mode='w', newline='') as csvfile:\n",
    "\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"image_path\", \"label\"])\n",
    "    \n",
    "    # Recorremos las carpetas de animales\n",
    "    for folder in os.listdir(main_folder):\n",
    "        folder_path = os.path.join(main_folder, folder)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            # Usamos el nombre de la carpeta como etiqueta\n",
    "            label = folder\n",
    "            \n",
    "            for image_file in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, image_file)\n",
    "                \n",
    "                writer.writerow([image_path, label])\n",
    "\n",
    "print(f\"Etiquetas generadas en {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamos los datos del csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"image_labels.csv\"\n",
    "\n",
    "image_size = (64, 64)\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "# cargamos las imágenes y etiquetas del csv\n",
    "processed_images = []\n",
    "with open(csv_file, mode='r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        image_path = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        \n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.resize(image_size).convert(\"L\")\n",
    "                img_array = np.array(img)  \n",
    "                processed_images.append(img_array)\n",
    "                labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {image_path}: {e}\")\n",
    "\n",
    "\n",
    "# Convertimos las listas a array de NumPy\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos los datos de nuestro csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"image_labels.csv\"\n",
    "image_size = (64, 64)\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "with open(csv_file, mode='r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        image_path = row[\"image_path\"]\n",
    "        label = row[\"label\"]\n",
    "        \n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.resize(image_size).convert(\"L\")\n",
    "                images.append(np.array(img))\n",
    "                labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {image_path}: {e}\")\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para poder elegir diferentes extractores de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, methods=None):\n",
    "    all_features = []\n",
    "    \n",
    "    for img in images:\n",
    "        img_features = []\n",
    "        \n",
    "        if len(img.shape) > 2:\n",
    "            img = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])  \n",
    "        \n",
    "        if not methods:  # Si no se especifican métodos\n",
    "            img_features = img.flatten()\n",
    "        else:\n",
    "            for method in methods:\n",
    "                feature = None\n",
    "                # Méthodo HOG\n",
    "                if method == \"hog\":\n",
    "                    feature = hog(\n",
    "                        img, \n",
    "                        orientations=9, \n",
    "                        pixels_per_cell=(8, 8),\n",
    "                        cells_per_block=(2, 2), \n",
    "                        block_norm='L2-Hys', \n",
    "                        visualize=False\n",
    "                    )\n",
    "                # Método rft\n",
    "                elif method == \"rft\":\n",
    "                    fft = np.abs(fft2(img))\n",
    "                    radial_profile = fft.mean(axis=1) \n",
    "                    feature = radial_profile\n",
    "\n",
    "                # Método lbp\n",
    "                elif method == \"lbp\":\n",
    "                    radius = 1\n",
    "                    n_points = 8 * radius\n",
    "                    lbp = local_binary_pattern(img, n_points, radius, method=\"uniform\")\n",
    "                    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "                    lbp_hist = lbp_hist.astype(np.float32)\n",
    "                    lbp_hist /= (lbp_hist.sum() + 1e-6)  # Normalizar\n",
    "                    feature = lbp_hist\n",
    "                    \n",
    "                else:\n",
    "                    raise ValueError(f\"Método desconocido: {method}\")\n",
    "\n",
    "                if feature is not None:\n",
    "                    img_features.extend(feature.flatten())\n",
    "        \n",
    "        all_features.append(img_features)\n",
    "    \n",
    "    # Convertir lista a un array numpy, rellenar con ceros si las longitudes varían\n",
    "    max_len = max(len(f) for f in all_features)\n",
    "    feature_array = np.array([np.pad(f, (0, max_len - len(f)), mode='constant') for f in all_features])\n",
    "    return feature_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos una función para aplicar el downsampling a las clases flamingo y emu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución inicial:\n",
      "Counter({np.str_('elephant'): 64, np.str_('flamingo'): 59, np.str_('rhino'): 59, np.str_('emu'): 53})\n",
      "Distribución después del balanceo:\n",
      "Counter({np.str_('elephant'): 64, np.str_('flamingo'): 59, np.str_('rhino'): 59, np.str_('emu'): 53})\n"
     ]
    }
   ],
   "source": [
    "def balance_classes(images, labels):\n",
    "    label_counts = Counter(labels)\n",
    "    print(\"Distribución inicial:\")\n",
    "    print(label_counts)\n",
    "\n",
    "    # Determinamos el número mínimo de ejemplos entre \"rhino\" y \"elephant\"\n",
    "    rhino_count = label_counts['rhino']\n",
    "    elephant_count = label_counts['elephant']\n",
    "    \n",
    "    # Se usa el mínimo de \"rhino\" y \"elephant\" para balancear las clases\n",
    "    min_count = min(rhino_count, elephant_count)\n",
    "\n",
    "    balanced_images = []\n",
    "    balanced_labels = []\n",
    "\n",
    "    for class_label in ['flamingo', 'emu', 'elephant', 'rhino']:\n",
    "        class_indices = np.where(labels == class_label)[0]\n",
    "        \n",
    "        if class_label in ['flamingo', 'emu']:\n",
    "            # Para \"flamingo\" y \"emu\", balancear reduciendo su número al mínimo entre sus propios ejemplos o min_count\n",
    "            target_count = min(min_count, len(class_indices))  \n",
    "            selected_indices = np.random.choice(class_indices, target_count, replace=False)\n",
    "\n",
    "            balanced_images.extend(images[selected_indices])\n",
    "            balanced_labels.extend(labels[selected_indices])\n",
    "\n",
    "        else:\n",
    "            # Para \"elephant\" y \"rhino\", no eliminamos nada, solo agregamos las imágenes\n",
    "            balanced_images.extend(images[class_indices])\n",
    "            balanced_labels.extend(labels[class_indices])\n",
    "\n",
    "    balanced_images = np.array(balanced_images)\n",
    "    balanced_labels = np.array(balanced_labels)\n",
    "\n",
    "    print(\"Distribución después del balanceo:\")\n",
    "    print(Counter(balanced_labels))\n",
    "\n",
    "    return balanced_images, balanced_labels\n",
    "\n",
    "\n",
    "\n",
    "images, labels = balance_classes(images, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizamos el entrenamiento con k-folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución inicial:\n",
      "Counter({np.str_('elephant'): 64, np.str_('flamingo'): 59, np.str_('rhino'): 59, np.str_('emu'): 53})\n",
      "Distribución después del balanceo:\n",
      "Counter({np.str_('elephant'): 64, np.str_('flamingo'): 59, np.str_('rhino'): 59, np.str_('emu'): 53})\n",
      "\n",
      "Fold 1/15\n",
      "\n",
      "Fold 1/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.80      1.00      0.89         4\n",
      "         emu       0.00      0.00      0.00         4\n",
      "    flamingo       0.60      0.75      0.67         4\n",
      "       rhino       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.55      0.69      0.61        16\n",
      "weighted avg       0.55      0.69      0.61        16\n",
      "\n",
      "Precisión en Fold 1: 0.6875\n",
      "F1 Score en Fold 1: 0.6111\n",
      "Precisión en Fold 1: 0.5500\n",
      "Recall en Fold 1: 0.6875\n",
      "\n",
      "Fold 2/15\n",
      "\n",
      "Fold 2/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       1.00      1.00      1.00         4\n",
      "         emu       1.00      0.75      0.86         4\n",
      "    flamingo       0.80      1.00      0.89         4\n",
      "       rhino       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.95      0.94      0.94        16\n",
      "weighted avg       0.95      0.94      0.94        16\n",
      "\n",
      "Precisión en Fold 2: 0.9375\n",
      "F1 Score en Fold 2: 0.9365\n",
      "Precisión en Fold 2: 0.9500\n",
      "Recall en Fold 2: 0.9375\n",
      "\n",
      "Fold 3/15\n",
      "\n",
      "Fold 3/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.50      0.75      0.60         4\n",
      "         emu       0.67      0.50      0.57         4\n",
      "    flamingo       0.75      0.75      0.75         4\n",
      "       rhino       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.65      0.62      0.62        16\n",
      "weighted avg       0.65      0.62      0.62        16\n",
      "\n",
      "Precisión en Fold 3: 0.6250\n",
      "F1 Score en Fold 3: 0.6232\n",
      "Precisión en Fold 3: 0.6458\n",
      "Recall en Fold 3: 0.6250\n",
      "\n",
      "Fold 4/15\n",
      "\n",
      "Fold 4/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.50      0.50      0.50         4\n",
      "         emu       1.00      0.75      0.86         4\n",
      "    flamingo       0.80      1.00      0.89         4\n",
      "       rhino       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.76      0.75      0.75        16\n",
      "weighted avg       0.76      0.75      0.75        16\n",
      "\n",
      "Precisión en Fold 4: 0.7500\n",
      "F1 Score en Fold 4: 0.7490\n",
      "Precisión en Fold 4: 0.7625\n",
      "Recall en Fold 4: 0.7500\n",
      "\n",
      "Fold 5/15\n",
      "\n",
      "Fold 5/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.80      1.00      0.89         4\n",
      "         emu       0.60      0.75      0.67         4\n",
      "    flamingo       0.75      0.75      0.75         4\n",
      "       rhino       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.75        16\n",
      "   macro avg       0.79      0.75      0.74        16\n",
      "weighted avg       0.79      0.75      0.74        16\n",
      "\n",
      "Precisión en Fold 5: 0.7500\n",
      "F1 Score en Fold 5: 0.7431\n",
      "Precisión en Fold 5: 0.7875\n",
      "Recall en Fold 5: 0.7500\n",
      "\n",
      "Fold 6/15\n",
      "\n",
      "Fold 6/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.75      0.75      0.75         4\n",
      "         emu       0.75      0.75      0.75         4\n",
      "    flamingo       0.80      1.00      0.89         4\n",
      "       rhino       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.82      0.81      0.81        16\n",
      "weighted avg       0.82      0.81      0.81        16\n",
      "\n",
      "Precisión en Fold 6: 0.8125\n",
      "F1 Score en Fold 6: 0.8115\n",
      "Precisión en Fold 6: 0.8250\n",
      "Recall en Fold 6: 0.8125\n",
      "\n",
      "Fold 7/15\n",
      "\n",
      "Fold 7/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.60      0.75      0.67         4\n",
      "         emu       0.40      0.50      0.44         4\n",
      "    flamingo       1.00      0.75      0.86         4\n",
      "       rhino       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.75      0.69      0.71        16\n",
      "weighted avg       0.75      0.69      0.71        16\n",
      "\n",
      "Precisión en Fold 7: 0.6875\n",
      "F1 Score en Fold 7: 0.7063\n",
      "Precisión en Fold 7: 0.7500\n",
      "Recall en Fold 7: 0.6875\n",
      "\n",
      "Fold 8/15\n",
      "\n",
      "Fold 8/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.57      0.80      0.67         5\n",
      "         emu       0.00      0.00      0.00         3\n",
      "    flamingo       0.67      0.50      0.57         4\n",
      "       rhino       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.51      0.57      0.53        16\n",
      "weighted avg       0.55      0.62      0.57        16\n",
      "\n",
      "Precisión en Fold 8: 0.6250\n",
      "F1 Score en Fold 8: 0.5734\n",
      "Precisión en Fold 8: 0.5452\n",
      "Recall en Fold 8: 0.6250\n",
      "\n",
      "Fold 9/15\n",
      "\n",
      "Fold 9/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.67      0.80      0.73         5\n",
      "         emu       0.67      0.67      0.67         3\n",
      "    flamingo       0.75      0.75      0.75         4\n",
      "       rhino       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.69      0.68      0.68        16\n",
      "weighted avg       0.69      0.69      0.68        16\n",
      "\n",
      "Precisión en Fold 9: 0.6875\n",
      "F1 Score en Fold 9: 0.6826\n",
      "Precisión en Fold 9: 0.6875\n",
      "Recall en Fold 9: 0.6875\n",
      "\n",
      "Fold 10/15\n",
      "\n",
      "Fold 10/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       1.00      0.40      0.57         5\n",
      "         emu       0.60      1.00      0.75         3\n",
      "    flamingo       1.00      0.50      0.67         4\n",
      "       rhino       0.57      1.00      0.73         4\n",
      "\n",
      "    accuracy                           0.69        16\n",
      "   macro avg       0.79      0.72      0.68        16\n",
      "weighted avg       0.82      0.69      0.67        16\n",
      "\n",
      "Precisión en Fold 10: 0.6875\n",
      "F1 Score en Fold 10: 0.6677\n",
      "Precisión en Fold 10: 0.8179\n",
      "Recall en Fold 10: 0.6875\n",
      "\n",
      "Fold 11/15\n",
      "\n",
      "Fold 11/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.83      1.00      0.91         5\n",
      "         emu       1.00      0.00      0.00         3\n",
      "    flamingo       0.60      0.75      0.67         4\n",
      "       rhino       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.80      0.69      0.61        15\n",
      "weighted avg       0.79      0.73      0.65        15\n",
      "\n",
      "Precisión en Fold 11: 0.7333\n",
      "F1 Score en Fold 11: 0.6522\n",
      "Precisión en Fold 11: 0.5878\n",
      "Recall en Fold 11: 0.7333\n",
      "\n",
      "Fold 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\108057\\OneDrive - Universidade da Coruña\\FIC\\AÑO3\\CUATRI1\\PRINCIPIOS\\entorno PVC\\entorno_PVC\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 12/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.67      0.50      0.57         4\n",
      "         emu       1.00      0.33      0.50         3\n",
      "    flamingo       0.80      1.00      0.89         4\n",
      "       rhino       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.74      0.65      0.64        15\n",
      "weighted avg       0.72      0.67      0.65        15\n",
      "\n",
      "Precisión en Fold 12: 0.6667\n",
      "F1 Score en Fold 12: 0.6494\n",
      "Precisión en Fold 12: 0.7244\n",
      "Recall en Fold 12: 0.6667\n",
      "\n",
      "Fold 13/15\n",
      "\n",
      "Fold 13/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       1.00      0.75      0.86         4\n",
      "         emu       0.67      0.67      0.67         3\n",
      "    flamingo       1.00      0.75      0.86         4\n",
      "       rhino       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.83      0.79      0.80        15\n",
      "weighted avg       0.84      0.80      0.80        15\n",
      "\n",
      "Precisión en Fold 13: 0.8000\n",
      "F1 Score en Fold 13: 0.8038\n",
      "Precisión en Fold 13: 0.8444\n",
      "Recall en Fold 13: 0.8000\n",
      "\n",
      "Fold 14/15\n",
      "\n",
      "Fold 14/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.80      1.00      0.89         4\n",
      "         emu       1.00      0.33      0.50         3\n",
      "    flamingo       1.00      1.00      1.00         4\n",
      "       rhino       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.90      0.83      0.82        15\n",
      "weighted avg       0.89      0.87      0.84        15\n",
      "\n",
      "Precisión en Fold 14: 0.8667\n",
      "F1 Score en Fold 14: 0.8407\n",
      "Precisión en Fold 14: 0.8933\n",
      "Recall en Fold 14: 0.8667\n",
      "\n",
      "Fold 15/15\n",
      "\n",
      "Fold 15/15 Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    elephant       0.80      1.00      0.89         4\n",
      "         emu       0.75      0.75      0.75         4\n",
      "    flamingo       0.67      0.67      0.67         3\n",
      "       rhino       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.80      0.79      0.79        15\n",
      "weighted avg       0.81      0.80      0.80        15\n",
      "\n",
      "Precisión en Fold 15: 0.8000\n",
      "F1 Score en Fold 15: 0.7989\n",
      "Precisión en Fold 15: 0.8133\n",
      "Recall en Fold 15: 0.8000\n",
      "\n",
      "Resultados de k-Fold Cross-Validation:\n",
      "------------------------------------------------------------------\n",
      "Exactitud promedio: 0.7411\n",
      "Desviación estándar de la exactitud: 0.0859\n",
      "------------------------------------------------------------------\n",
      "F1 Score promedio: 0.7233\n",
      "Desviación estándar del F1 Score: 0.0969\n",
      "------------------------------------------------------------------\n",
      "Precisión promedio: 0.7457\n",
      "Desviación estándar de la precisión: 0.1179\n",
      "------------------------------------------------------------------\n",
      "Recall promedio: 0.7411\n",
      "Desviación estándar del recall: 0.0859\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images, labels = balance_classes(images, labels)\n",
    "features = extract_features(images, methods = [\"hog\"])\n",
    "\n",
    "k = 15\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Creamos listas para guardar los valores correspondientes en cada fold\n",
    "fold_accuracies = []  \n",
    "fold_f1_scores = []   \n",
    "fold_precisions = []  \n",
    "fold_recalls = []     \n",
    "fold_dice_scores = [] \n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(features, labels)):\n",
    "    print(f\"\\nFold {fold + 1}/{k}\")\n",
    "    \n",
    "    # División de los datos en train y test para este fold\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    \n",
    "    # Ajusta los pesos: más peso para 'elephant' y 'rhino'\n",
    "    class_weights = {'elephant': 2, 'rhino': 2, 'flamingo': 1, 'emu': 1}\n",
    "\n",
    "    rf_model = RandomForestClassifier(class_weight=class_weights, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)  \n",
    "\n",
    "    # Predicciones en el conjunto de test\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # Predicciones por clase en conjunto test\n",
    "    print(f\"\\nFold {fold + 1}/{k} Reporte de Clasificación:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=1))  \n",
    "    \n",
    "    # Calculamos las métricas y las guardamos\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "    \n",
    "    fold_accuracies.append(accuracy)\n",
    "    fold_f1_scores.append(f1)\n",
    "    fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall)\n",
    "    \n",
    "    print(f\"Precisión en Fold {fold + 1}: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score en Fold {fold + 1}: {f1:.4f}\")\n",
    "    print(f\"Precisión en Fold {fold + 1}: {precision:.4f}\")\n",
    "    print(f\"Recall en Fold {fold + 1}: {recall:.4f}\")\n",
    "\n",
    "# Resultados finales\n",
    "print(\"\\nResultados de k-Fold Cross-Validation:\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(f\"Exactitud promedio: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Desviación estándar de la exactitud: {np.std(fold_accuracies):.4f}\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(f\"F1 Score promedio: {np.mean(fold_f1_scores):.4f}\")\n",
    "print(f\"Desviación estándar del F1 Score: {np.std(fold_f1_scores):.4f}\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(f\"Precisión promedio: {np.mean(fold_precisions):.4f}\")\n",
    "print(f\"Desviación estándar de la precisión: {np.std(fold_precisions):.4f}\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(f\"Recall promedio: {np.mean(fold_recalls):.4f}\")\n",
    "print(f\"Desviación estándar del recall: {np.std(fold_recalls):.4f}\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_PVC",
   "language": "python",
   "name": "entorno_pvc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
